# -*- coding: utf-8 -*-
"""Housepriceprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pek02HsWA-k4ScGzYZBoix2GmmaA3TfX
"""

import pandas as pd

df=pd.read_csv('/HousePricePrediction.xlsx - Sheet1.csv')

df.shape

df.head()

df.shape

df.drop(columns=['Id'],inplace=True) # Id column isnot useful so deleting it.

df.isna().sum() #checking the number of null values

from sklearn.impute import SimpleImputer
imputer=SimpleImputer(strategy='mean')
imputer.fit(df[['SalePrice']]) #using imputation technique to full null values with mean.

imputer.statistics_

df['SalePrice'] = imputer.transform(df[['SalePrice']])

df.isna().sum()

df=df.fillna(0) #filling remaining null values with 0.

df.isna().sum()

df.describe() #we can see presence of outlier in LotArea from 75% and max.

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('darkgrid')

sns.boxplot(df,y='LotArea')

import numpy as np

Q1=np.percentile(df['LotArea'],25,interpolation='midpoint') #Q1 for first 25% of data
Q3=np.percentile(df['LotArea'],75,interpolation='midpoint') #Q3 for first 75% of data

IQR=Q3-Q1

lowerbound=Q1-1.5*IQR
upperbound=Q3+1.5*IQR

df=df[(df.LotArea<upperbound) & (df.LotArea>lowerbound)]

df.shape

df.info()

df

cat_col= df.select_dtypes('object').columns.tolist()

cat_col

from sklearn.preprocessing import OneHotEncoder
encoder=OneHotEncoder(sparse=False,handle_unknown='ignore')

# Convert all columns in cat_col to string type
for col in cat_col:
    df[col] = df[col].astype(str)  # Ensure all values are strings

encoder.fit(df[cat_col])

encoded_cols=encoder.get_feature_names_out(cat_col)

encoded_cols

df[encoded_cols]=encoder.transform(df[cat_col])

df

df.drop(columns=cat_col,inplace=True)

df

df.columns

X=df.drop(columns=['SalePrice'])
Y=df['SalePrice']

X

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
scaler.fit(X)

X[:]=scaler.transform(X)

X

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

X_train.shape,X_test.shape,Y_train.shape,Y_test.shape

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(X_train,Y_train)

Y_pred=model.predict(X_test)

Y_test[:5]

Y_pred[:5]

from sklearn.metrics import mean_absolute_error

mean_absolute_error(Y_test,Y_pred)

from sklearn.linear_model import Lasso
lasso_model=Lasso(alpha=0.1,max_iter=100,tol=0.1)
lasso_model.fit(X_train,Y_train)

lasso_pred=lasso_model.predict(X_test)

mean_absolute_error(Y_test,lasso_pred)

from sklearn.linear_model import Ridge
Ridge_model=Ridge(alpha=0.1,max_iter=100,tol=0.1)
Ridge_model.fit(X_train,Y_train)

Ridge_pred=Ridge_model.predict(X_test)
mean_absolute_error(Y_test,Ridge_pred)

#L2 regression has produced better result.